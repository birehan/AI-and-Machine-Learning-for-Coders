{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Features in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 13:21:30.759680: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 13:21:30.813731: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 13:21:30.814874: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-13 13:21:32.027086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "data =  tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_lables) = data.load_data()\n",
    "training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 10:37:43.167164: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   4/1875 [..............................] - ETA: 42s - loss: 0.2383 - accuracy: 0.9141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 10:39:59.041195: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 44s 23ms/step - loss: 0.2645 - accuracy: 0.9029\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2287 - accuracy: 0.9153\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1995 - accuracy: 0.9258\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.1765 - accuracy: 0.9341\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1564 - accuracy: 0.9402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7781b3f09e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2775 - accuracy: 0.8993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27753880620002747, 0.8992999792098999]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step\n",
      "[2.6980675e-07 2.4123286e-09 2.3320785e-09 4.4448800e-09 1.4464906e-10\n",
      " 4.7101175e-06 8.6295221e-10 1.2947056e-06 3.2780804e-07 9.9999326e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_lables[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a CNN to Distinguish Between Horses and Humans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Keras ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m training_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorse-or-human.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m training_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/horse-or-human/training/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m zip_ref \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZipFile(training_file_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m zip_ref\u001b[38;5;241m.\u001b[39mextractall(training_dir)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/urllib/request.py:276\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    273\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "training_url = \"https://storage.googleapis.com/learning-datasets/horse-or-human.zip\"\n",
    "training_file_name = \"horse-or-human.zip\"\n",
    "training_dir = '../data/horse-or-human/training/'\n",
    "urllib.request.urlretrieve(training_url, training_file_name)\n",
    "\n",
    "zip_ref = zipfile.ZipFile(training_file_name, 'r')\n",
    "zip_ref.extractall(training_dir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import  ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "training_dir = '../data/horse-or-human/training/'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(300, 300),\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Architecture for Horses or Humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 13:21:38.628930: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-13 13:21:38.735206: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 43655168 exceeds 10% of free system memory.\n",
      "2024-11-13 13:21:38.752361: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 43655168 exceeds 10% of free system memory.\n",
      "2024-11-13 13:21:38.761309: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 43655168 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#     tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#     tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#     tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#     tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(512, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # tf.keras.layers.Dropout(0.5),  # Add dropout to reduce overfitting\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 149, 149, 8)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 73, 73, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 85264)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               10913920  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10915441 (41.64 MB)\n",
      "Trainable params: 10915441 (41.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 13:21:41.718756: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 43655168 exceeds 10% of free system memory.\n",
      "2024-11-13 13:21:42.210960: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 43655168 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 25s 720ms/step - loss: 1.6606 - accuracy: 0.6641\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 26s 767ms/step - loss: 0.3585 - accuracy: 0.8617\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 25s 738ms/step - loss: 0.1831 - accuracy: 0.9299\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 25s 744ms/step - loss: 0.1047 - accuracy: 0.9679\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 24s 732ms/step - loss: 0.0477 - accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 25s 757ms/step - loss: 0.0290 - accuracy: 0.9922\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 28s 841ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 27s 819ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 27s 808ms/step - loss: 0.0517 - accuracy: 0.9834\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 26s 792ms/step - loss: 0.0046 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Assuming train_generator is already defined\n",
    "history = model.fit(train_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Validation to the Horses or Humans Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_url = \"https://storage.googleapis.com/learning-datasets/validation-horse-or-human.zip\"\n",
    "validation_file_name = \"validation-horse-or-human.zip\"\n",
    "validation_dir = 'horse-or-human/validation/'\n",
    "urllib.request.urlretrieve(validation_url, validation_file_name)\n",
    "zip_ref = zipfile.ZipFile(validation_file_name, 'r')\n",
    "zip_ref.extractall(validation_dir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "validation_dir,\n",
    "target_size=(300, 300),\n",
    "class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1251173/1497470093.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33/33 [==============================] - 27s 820ms/step - loss: 1.1486e-04 - accuracy: 1.0000 - val_loss: 2.0980 - val_accuracy: 0.8281\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 28s 832ms/step - loss: 4.6620e-05 - accuracy: 1.0000 - val_loss: 2.4031 - val_accuracy: 0.8164\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 26s 793ms/step - loss: 7.2739e-05 - accuracy: 1.0000 - val_loss: 2.1717 - val_accuracy: 0.8320\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 27s 802ms/step - loss: 2.9631e-05 - accuracy: 1.0000 - val_loss: 2.1040 - val_accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 27s 798ms/step - loss: 5.0797e-05 - accuracy: 1.0000 - val_loss: 2.1125 - val_accuracy: 0.8477\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 26s 808ms/step - loss: 2.2294e-05 - accuracy: 1.0000 - val_loss: 2.1332 - val_accuracy: 0.8477\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 25s 765ms/step - loss: 9.9980e-06 - accuracy: 1.0000 - val_loss: 2.2471 - val_accuracy: 0.8477\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 25s 759ms/step - loss: 9.1002e-06 - accuracy: 1.0000 - val_loss: 2.5282 - val_accuracy: 0.8359\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 27s 799ms/step - loss: 5.9304e-06 - accuracy: 1.0000 - val_loss: 2.3063 - val_accuracy: 0.8516\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 29s 882ms/step - loss: 5.9451e-06 - accuracy: 1.0000 - val_loss: 2.6069 - val_accuracy: 0.8438\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Horse or Human Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "../data/download.jpeg is a horse\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "path = '../data/download.jpeg'\n",
    "img = image.load_img(path, target_size=(300, 300))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "image_tensor = np.vstack([x])\n",
    "classes = model.predict(image_tensor)\n",
    "\n",
    "if classes[0]>0.5:\n",
    "    print(path + \" is a human\")\n",
    "else:\n",
    "    print(path + \" is a horse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation\n",
    "\n",
    "- create additional new data by amending what it has using a number of transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weights_file = \"inception_v3.h5\"\n",
    "\n",
    "urllib.request.urlretrieve(weights_url, weights_file)\n",
    "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
    "include_top=False,\n",
    "weights=None)\n",
    "\n",
    "pre_trained_model.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)          (None, 74, 74, 32)           864       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (None, 74, 74, 32)           96        ['conv2d_96[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_94 (Activation)  (None, 74, 74, 32)           0         ['batch_normalization_94[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)          (None, 72, 72, 32)           9216      ['activation_94[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (None, 72, 72, 32)           96        ['conv2d_97[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_95 (Activation)  (None, 72, 72, 32)           0         ['batch_normalization_95[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)          (None, 72, 72, 64)           18432     ['activation_95[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_96 (Ba  (None, 72, 72, 64)           192       ['conv2d_98[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_96 (Activation)  (None, 72, 72, 64)           0         ['batch_normalization_96[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 35, 35, 64)           0         ['activation_96[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)          (None, 35, 35, 80)           5120      ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_97 (Ba  (None, 35, 35, 80)           240       ['conv2d_99[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_97 (Activation)  (None, 35, 35, 80)           0         ['batch_normalization_97[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)         (None, 33, 33, 192)          138240    ['activation_97[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_98 (Ba  (None, 33, 33, 192)          576       ['conv2d_100[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_98 (Activation)  (None, 33, 33, 192)          0         ['batch_normalization_98[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 16, 16, 192)          0         ['activation_98[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_102 (B  (None, 16, 16, 64)           192       ['conv2d_104[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_102 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_102[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)         (None, 16, 16, 48)           9216      ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_102[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_100 (B  (None, 16, 16, 48)           144       ['conv2d_102[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_103 (B  (None, 16, 16, 96)           288       ['conv2d_105[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_100 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_100[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_103 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_103[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_9 (Avera  (None, 16, 16, 192)          0         ['max_pooling2d_7[0][0]']     \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_100[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_103[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)         (None, 16, 16, 32)           6144      ['average_pooling2d_9[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_99 (Ba  (None, 16, 16, 64)           192       ['conv2d_101[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_101 (B  (None, 16, 16, 64)           192       ['conv2d_103[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_104 (B  (None, 16, 16, 96)           288       ['conv2d_106[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_105 (B  (None, 16, 16, 32)           96        ['conv2d_107[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_99 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_99[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_101 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_101[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_104 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_104[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_105 (Activation  (None, 16, 16, 32)           0         ['batch_normalization_105[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_99[0][0]',       \n",
      "                                                                     'activation_101[0][0]',      \n",
      "                                                                     'activation_104[0][0]',      \n",
      "                                                                     'activation_105[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_109 (B  (None, 16, 16, 64)           192       ['conv2d_111[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_109 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_109[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)         (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_109[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_107 (B  (None, 16, 16, 48)           144       ['conv2d_109[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_110 (B  (None, 16, 16, 96)           288       ['conv2d_112[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_107 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_107[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_110 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_110[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_10 (Aver  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_107[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_110[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)         (None, 16, 16, 64)           16384     ['average_pooling2d_10[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_106 (B  (None, 16, 16, 64)           192       ['conv2d_108[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_108 (B  (None, 16, 16, 64)           192       ['conv2d_110[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_111 (B  (None, 16, 16, 96)           288       ['conv2d_113[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_112 (B  (None, 16, 16, 64)           192       ['conv2d_114[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_106 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_106[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_108 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_108[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_111 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_111[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_112 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_112[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_106[0][0]',      \n",
      "                                                                     'activation_108[0][0]',      \n",
      "                                                                     'activation_111[0][0]',      \n",
      "                                                                     'activation_112[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_116 (B  (None, 16, 16, 64)           192       ['conv2d_118[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_116 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_116[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)         (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_116[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_114 (B  (None, 16, 16, 48)           144       ['conv2d_116[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_117 (B  (None, 16, 16, 96)           288       ['conv2d_119[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_114 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_114[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_117 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_117[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_11 (Aver  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_114[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_117[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)         (None, 16, 16, 64)           18432     ['average_pooling2d_11[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_113 (B  (None, 16, 16, 64)           192       ['conv2d_115[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_115 (B  (None, 16, 16, 64)           192       ['conv2d_117[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_118 (B  (None, 16, 16, 96)           288       ['conv2d_120[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_119 (B  (None, 16, 16, 64)           192       ['conv2d_121[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_113 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_113[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_115 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_115[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_118 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_118[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_119 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_119[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_113[0][0]',      \n",
      "                                                                     'activation_115[0][0]',      \n",
      "                                                                     'activation_118[0][0]',      \n",
      "                                                                     'activation_119[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_121 (B  (None, 16, 16, 64)           192       ['conv2d_123[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_121 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_121[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_121[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_122 (B  (None, 16, 16, 96)           288       ['conv2d_124[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_122 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_122[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)         (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_122[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_120 (B  (None, 7, 7, 384)            1152      ['conv2d_122[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_123 (B  (None, 7, 7, 96)             288       ['conv2d_125[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_120 (Activation  (None, 7, 7, 384)            0         ['batch_normalization_120[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_123 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_123[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 7, 7, 288)            0         ['mixed2[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_120[0][0]',      \n",
      "                                                                     'activation_123[0][0]',      \n",
      "                                                                     'max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_128 (B  (None, 7, 7, 128)            384       ['conv2d_130[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_128 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_128[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_128[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_129 (B  (None, 7, 7, 128)            384       ['conv2d_131[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_129 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_129[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_129[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_125 (B  (None, 7, 7, 128)            384       ['conv2d_127[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_130 (B  (None, 7, 7, 128)            384       ['conv2d_132[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_125 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_125[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_130 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_130[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_125[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_130[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_126 (B  (None, 7, 7, 128)            384       ['conv2d_128[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_131 (B  (None, 7, 7, 128)            384       ['conv2d_133[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_126 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_126[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_131 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_131[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_12 (Aver  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_126[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_131[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_12[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_124 (B  (None, 7, 7, 192)            576       ['conv2d_126[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_127 (B  (None, 7, 7, 192)            576       ['conv2d_129[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_132 (B  (None, 7, 7, 192)            576       ['conv2d_134[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_133 (B  (None, 7, 7, 192)            576       ['conv2d_135[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_124 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_124[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_127 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_127[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_132 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_132[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_133 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_133[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_124[0][0]',      \n",
      "                                                                     'activation_127[0][0]',      \n",
      "                                                                     'activation_132[0][0]',      \n",
      "                                                                     'activation_133[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_138 (B  (None, 7, 7, 160)            480       ['conv2d_140[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_138 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_138[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_138[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_139 (B  (None, 7, 7, 160)            480       ['conv2d_141[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_139 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_139[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_139[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_135 (B  (None, 7, 7, 160)            480       ['conv2d_137[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_140 (B  (None, 7, 7, 160)            480       ['conv2d_142[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_135 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_135[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_140 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_140[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_135[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_140[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_136 (B  (None, 7, 7, 160)            480       ['conv2d_138[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_141 (B  (None, 7, 7, 160)            480       ['conv2d_143[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_136 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_136[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_141 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_141[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_13 (Aver  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_136[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_141[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_13[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_134 (B  (None, 7, 7, 192)            576       ['conv2d_136[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_137 (B  (None, 7, 7, 192)            576       ['conv2d_139[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_142 (B  (None, 7, 7, 192)            576       ['conv2d_144[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_143 (B  (None, 7, 7, 192)            576       ['conv2d_145[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_134 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_134[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_137 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_137[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_142 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_142[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_143 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_143[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_134[0][0]',      \n",
      "                                                                     'activation_137[0][0]',      \n",
      "                                                                     'activation_142[0][0]',      \n",
      "                                                                     'activation_143[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_148 (B  (None, 7, 7, 160)            480       ['conv2d_150[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_148 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_148[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_148[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_149 (B  (None, 7, 7, 160)            480       ['conv2d_151[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_149 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_149[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_149[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_145 (B  (None, 7, 7, 160)            480       ['conv2d_147[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_150 (B  (None, 7, 7, 160)            480       ['conv2d_152[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_145 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_145[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_150 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_150[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_145[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_150[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_146 (B  (None, 7, 7, 160)            480       ['conv2d_148[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_151 (B  (None, 7, 7, 160)            480       ['conv2d_153[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_146 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_146[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_151 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_151[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_14 (Aver  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_146[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_151[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_14[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_144 (B  (None, 7, 7, 192)            576       ['conv2d_146[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_147 (B  (None, 7, 7, 192)            576       ['conv2d_149[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_152 (B  (None, 7, 7, 192)            576       ['conv2d_154[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_153 (B  (None, 7, 7, 192)            576       ['conv2d_155[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_144 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_144[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_147 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_147[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_152 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_152[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_153 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_153[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_144[0][0]',      \n",
      "                                                                     'activation_147[0][0]',      \n",
      "                                                                     'activation_152[0][0]',      \n",
      "                                                                     'activation_153[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_158 (B  (None, 7, 7, 192)            576       ['conv2d_160[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_158 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_158[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_158[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_159 (B  (None, 7, 7, 192)            576       ['conv2d_161[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_159 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_159[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_159[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_155 (B  (None, 7, 7, 192)            576       ['conv2d_157[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_160 (B  (None, 7, 7, 192)            576       ['conv2d_162[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_155 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_155[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_160 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_160[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_155[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_160[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_156 (B  (None, 7, 7, 192)            576       ['conv2d_158[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_161 (B  (None, 7, 7, 192)            576       ['conv2d_163[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_156 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_156[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_161 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_161[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_15 (Aver  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_156[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_164 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_161[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_165 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_15[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_154 (B  (None, 7, 7, 192)            576       ['conv2d_156[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_157 (B  (None, 7, 7, 192)            576       ['conv2d_159[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_162 (B  (None, 7, 7, 192)            576       ['conv2d_164[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_163 (B  (None, 7, 7, 192)            576       ['conv2d_165[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_154 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_154[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_157 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_157[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_162 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_162[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_163 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_163[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_154[0][0]',      \n",
      "                                                                     'activation_157[0][0]',      \n",
      "                                                                     'activation_162[0][0]',      \n",
      "                                                                     'activation_163[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_166 (B  (None, 7, 7, 192)            576       ['conv2d_168[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_166 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_166[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_166[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_167 (B  (None, 7, 7, 192)            576       ['conv2d_169[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_167 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_167[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_166 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_167[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_164 (B  (None, 7, 7, 192)            576       ['conv2d_166[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_168 (B  (None, 7, 7, 192)            576       ['conv2d_170[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_164 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_164[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_168 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_168[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_167 (Conv2D)         (None, 3, 3, 320)            552960    ['activation_164[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_171 (Conv2D)         (None, 3, 3, 192)            331776    ['activation_168[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_165 (B  (None, 3, 3, 320)            960       ['conv2d_167[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_169 (B  (None, 3, 3, 192)            576       ['conv2d_171[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_165 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_165[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_169 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_169[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 3, 3, 768)            0         ['mixed7[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)        (None, 3, 3, 1280)           0         ['activation_165[0][0]',      \n",
      "                                                                     'activation_169[0][0]',      \n",
      "                                                                     'max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_176 (Conv2D)         (None, 3, 3, 448)            573440    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_174 (B  (None, 3, 3, 448)            1344      ['conv2d_176[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_174 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_174[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_173 (Conv2D)         (None, 3, 3, 384)            491520    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_177 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_174[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_171 (B  (None, 3, 3, 384)            1152      ['conv2d_173[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_175 (B  (None, 3, 3, 384)            1152      ['conv2d_177[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_171 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_171[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_175 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_175[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_174 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_171[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_175 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_171[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_178 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_175[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_179 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_175[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling2d_16 (Aver  (None, 3, 3, 1280)           0         ['mixed8[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_172 (Conv2D)         (None, 3, 3, 320)            409600    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_172 (B  (None, 3, 3, 384)            1152      ['conv2d_174[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_173 (B  (None, 3, 3, 384)            1152      ['conv2d_175[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_176 (B  (None, 3, 3, 384)            1152      ['conv2d_178[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_177 (B  (None, 3, 3, 384)            1152      ['conv2d_179[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_180 (Conv2D)         (None, 3, 3, 192)            245760    ['average_pooling2d_16[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_170 (B  (None, 3, 3, 320)            960       ['conv2d_172[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_172 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_172[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_173 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_173[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_176 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_176[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_177 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_177[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_178 (B  (None, 3, 3, 192)            576       ['conv2d_180[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_170 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_170[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)      (None, 3, 3, 768)            0         ['activation_172[0][0]',      \n",
      "                                                                     'activation_173[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 3, 3, 768)            0         ['activation_176[0][0]',      \n",
      " )                                                                   'activation_177[0][0]']      \n",
      "                                                                                                  \n",
      " activation_178 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_178[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)        (None, 3, 3, 2048)           0         ['activation_170[0][0]',      \n",
      "                                                                     'mixed9_0[0][0]',            \n",
      "                                                                     'concatenate_2[0][0]',       \n",
      "                                                                     'activation_178[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_185 (Conv2D)         (None, 3, 3, 448)            917504    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_183 (B  (None, 3, 3, 448)            1344      ['conv2d_185[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_183 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_183[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_182 (Conv2D)         (None, 3, 3, 384)            786432    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_186 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_183[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_180 (B  (None, 3, 3, 384)            1152      ['conv2d_182[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_184 (B  (None, 3, 3, 384)            1152      ['conv2d_186[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_180 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_180[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_184 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_184[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_183 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_180[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_184 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_180[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_187 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_184[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_184[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling2d_17 (Aver  (None, 3, 3, 2048)           0         ['mixed9[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_181 (Conv2D)         (None, 3, 3, 320)            655360    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_181 (B  (None, 3, 3, 384)            1152      ['conv2d_183[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_182 (B  (None, 3, 3, 384)            1152      ['conv2d_184[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_185 (B  (None, 3, 3, 384)            1152      ['conv2d_187[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_186 (B  (None, 3, 3, 384)            1152      ['conv2d_188[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)         (None, 3, 3, 192)            393216    ['average_pooling2d_17[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_179 (B  (None, 3, 3, 320)            960       ['conv2d_181[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_181 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_181[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_182 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_182[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_185 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_185[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_186 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_186[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_187 (B  (None, 3, 3, 192)            576       ['conv2d_189[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_179 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_179[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)      (None, 3, 3, 768)            0         ['activation_181[0][0]',      \n",
      "                                                                     'activation_182[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 3, 3, 768)            0         ['activation_185[0][0]',      \n",
      " )                                                                   'activation_186[0][0]']      \n",
      "                                                                                                  \n",
      " activation_187 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_187[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)       (None, 3, 3, 2048)           0         ['activation_179[0][0]',      \n",
      "                                                                     'mixed9_1[0][0]',            \n",
      "                                                                     'concatenate_3[0][0]',       \n",
      "                                                                     'activation_187[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21802784 (83.17 MB)\n",
      "Trainable params: 21768352 (83.04 MB)\n",
      "Non-trainable params: 34432 (134.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape: (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print(f'last layer output shape: {last_layer.output_shape}')\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "flatten_layer = tf.keras.layers.Flatten()  # instantiate the layer\n",
    "x = flatten_layer(x)       # call it on the given tensor\n",
    "\n",
    "# Add a fully connected layer with 1, 024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: [[0.]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_trained_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# model.compile(optimizer=RMSprop(learning_rate=0.0001),\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#               loss='binary_crossentropy',\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#               metrics=['acc'])\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/site-packages/keras/src/engine/functional.py:167\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    159\u001b[0m         [\n\u001b[1;32m    160\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    162\u001b[0m         ]\n\u001b[1;32m    163\u001b[0m     ):\n\u001b[1;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    165\u001b[0m             inputs, outputs\n\u001b[1;32m    166\u001b[0m         )\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/site-packages/keras/src/engine/functional.py:209\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_history\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs\n\u001b[1;32m    206\u001b[0m     ):\n\u001b[1;32m    207\u001b[0m         base_layer_utils\u001b[38;5;241m.\u001b[39mcreate_keras_history(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nested_outputs)\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_graph_inputs_and_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# A Network does not create weights of its own, thus it is already\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# built.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/site-packages/keras/src/engine/functional.py:872\u001b[0m, in \u001b[0;36mFunctional._validate_graph_inputs_and_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_history\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    871\u001b[0m     cls_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 872\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput tensors of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model must be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe output of a TensorFlow `Layer` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(thus holding past layer metadata). Found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    876\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: [[0.]]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "# model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-13 15:12:41--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.171.251, 142.250.200.251, 142.250.201.27, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.171.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2024-11-13 15:12:43 ERROR 404: Not Found.\n",
      "\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget --no-check-certificate  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip  -O /tmp/rps.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m local_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/rps.zip\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m zip_ref \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_zip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m zip_ref\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m zip_ref\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/zipfile.py:1269\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1269\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.8/zipfile.py:1336\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip \\\n",
    "-O /tmp/rps.zip\n",
    "local_zip = '/tmp/rps.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/')\n",
    "zip_ref.close()\n",
    "TRAINING_DIR = \"/tmp/rps/\"\n",
    "training_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = training_datagen.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=(150,150),\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image:\n",
    "    # 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',\n",
    "    input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop',\n",
    "metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
