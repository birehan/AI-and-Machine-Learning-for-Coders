{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Public Datasets with TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 15:29:06.891515: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 29.45 MiB (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to /home/babi/tensorflow_datasets/fashion_mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cad7ab9a9d4c0a8459f9dd6c3dab5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1429c6c601440c8c6e87c2f05b6a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6f4a6721fe4efdae56a969675bbe24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a5aa410b8d4f7897ecfe082d9b6bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1e026826d843e988b11a75d4047fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 15:31:23.715866: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a6ea26691a4996b9393e434127f073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/babi/tensorflow_datasets/fashion_mnist/3.0.1.incompleteU0JR9U/fashion_mnist-train.tfrecord*...…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290cbae3b0a74c37a115434d2b3d9932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cdb6c115754f8197ebc43e27dd07a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/babi/tensorflow_datasets/fashion_mnist/3.0.1.incompleteU0JR9U/fashion_mnist-test.tfrecord*...:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset fashion_mnist downloaded and prepared to /home/babi/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "train\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "mnist_data = tfds.load(\"fashion_mnist\")\n",
    "for item in mnist_data:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "mnist_train = tfds.load(name=\"fashion_mnist\", split=\"train\")\n",
    "assert isinstance(mnist_train, tf.data.Dataset)\n",
    "print(type(mnist_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['image', 'label'])\n",
      "tf.Tensor(\n",
      "[[[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [ 77]\n",
      "  [227]\n",
      "  [227]\n",
      "  [208]\n",
      "  [210]\n",
      "  [225]\n",
      "  [216]\n",
      "  [ 85]\n",
      "  [ 32]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 61]\n",
      "  [100]\n",
      "  [ 97]\n",
      "  [ 80]\n",
      "  [ 57]\n",
      "  [117]\n",
      "  [227]\n",
      "  [238]\n",
      "  [115]\n",
      "  [ 49]\n",
      "  [ 78]\n",
      "  [106]\n",
      "  [108]\n",
      "  [ 71]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 81]\n",
      "  [105]\n",
      "  [ 80]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 64]\n",
      "  [ 44]\n",
      "  [ 21]\n",
      "  [ 13]\n",
      "  [ 44]\n",
      "  [ 69]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 80]\n",
      "  [114]\n",
      "  [ 80]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 26]\n",
      "  [ 92]\n",
      "  [ 69]\n",
      "  [ 68]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 71]\n",
      "  [ 74]\n",
      "  [ 83]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 83]\n",
      "  [ 77]\n",
      "  [108]\n",
      "  [ 34]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 55]\n",
      "  [ 92]\n",
      "  [ 69]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 71]\n",
      "  [ 71]\n",
      "  [ 77]\n",
      "  [ 69]\n",
      "  [ 66]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 80]\n",
      "  [ 78]\n",
      "  [ 94]\n",
      "  [ 63]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 63]\n",
      "  [ 95]\n",
      "  [ 66]\n",
      "  [ 68]\n",
      "  [ 72]\n",
      "  [ 72]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 77]\n",
      "  [106]\n",
      "  [ 61]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 80]\n",
      "  [108]\n",
      "  [ 71]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 71]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 78]\n",
      "  [ 72]\n",
      "  [ 85]\n",
      "  [128]\n",
      "  [ 64]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 88]\n",
      "  [120]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 77]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 83]\n",
      "  [ 83]\n",
      "  [ 66]\n",
      "  [111]\n",
      "  [123]\n",
      "  [ 78]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 85]\n",
      "  [134]\n",
      "  [ 74]\n",
      "  [ 85]\n",
      "  [ 69]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 81]\n",
      "  [ 75]\n",
      "  [ 61]\n",
      "  [151]\n",
      "  [115]\n",
      "  [ 91]\n",
      "  [ 12]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 10]\n",
      "  [ 85]\n",
      "  [153]\n",
      "  [ 83]\n",
      "  [ 80]\n",
      "  [ 68]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 68]\n",
      "  [ 61]\n",
      "  [162]\n",
      "  [122]\n",
      "  [ 78]\n",
      "  [  6]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 30]\n",
      "  [ 75]\n",
      "  [154]\n",
      "  [ 85]\n",
      "  [ 80]\n",
      "  [ 71]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 49]\n",
      "  [191]\n",
      "  [132]\n",
      "  [ 72]\n",
      "  [ 15]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 58]\n",
      "  [ 66]\n",
      "  [174]\n",
      "  [115]\n",
      "  [ 66]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [ 78]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 66]\n",
      "  [ 49]\n",
      "  [222]\n",
      "  [131]\n",
      "  [ 77]\n",
      "  [ 37]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 69]\n",
      "  [ 55]\n",
      "  [179]\n",
      "  [139]\n",
      "  [ 55]\n",
      "  [ 92]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 78]\n",
      "  [ 74]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 80]\n",
      "  [ 64]\n",
      "  [ 55]\n",
      "  [242]\n",
      "  [111]\n",
      "  [ 95]\n",
      "  [ 44]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 74]\n",
      "  [ 57]\n",
      "  [159]\n",
      "  [180]\n",
      "  [ 55]\n",
      "  [ 92]\n",
      "  [ 64]\n",
      "  [ 72]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 55]\n",
      "  [ 66]\n",
      "  [255]\n",
      "  [ 97]\n",
      "  [108]\n",
      "  [ 49]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 74]\n",
      "  [ 66]\n",
      "  [145]\n",
      "  [153]\n",
      "  [ 72]\n",
      "  [ 83]\n",
      "  [ 58]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 80]\n",
      "  [ 30]\n",
      "  [132]\n",
      "  [255]\n",
      "  [ 37]\n",
      "  [122]\n",
      "  [ 60]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 80]\n",
      "  [ 69]\n",
      "  [142]\n",
      "  [180]\n",
      "  [142]\n",
      "  [ 57]\n",
      "  [ 64]\n",
      "  [ 78]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 85]\n",
      "  [ 21]\n",
      "  [185]\n",
      "  [227]\n",
      "  [ 37]\n",
      "  [143]\n",
      "  [ 63]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 83]\n",
      "  [ 71]\n",
      "  [136]\n",
      "  [194]\n",
      "  [126]\n",
      "  [ 46]\n",
      "  [ 69]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 78]\n",
      "  [ 38]\n",
      "  [139]\n",
      "  [185]\n",
      "  [ 60]\n",
      "  [151]\n",
      "  [ 58]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  4]\n",
      "  [ 81]\n",
      "  [ 74]\n",
      "  [145]\n",
      "  [177]\n",
      "  [ 78]\n",
      "  [ 49]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 72]\n",
      "  [ 63]\n",
      "  [ 80]\n",
      "  [156]\n",
      "  [117]\n",
      "  [153]\n",
      "  [ 55]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 10]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [157]\n",
      "  [163]\n",
      "  [ 61]\n",
      "  [ 55]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 71]\n",
      "  [ 60]\n",
      "  [ 98]\n",
      "  [156]\n",
      "  [132]\n",
      "  [ 58]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 13]\n",
      "  [ 77]\n",
      "  [ 74]\n",
      "  [157]\n",
      "  [143]\n",
      "  [ 43]\n",
      "  [ 61]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 71]\n",
      "  [ 58]\n",
      "  [ 80]\n",
      "  [157]\n",
      "  [120]\n",
      "  [ 66]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [ 81]\n",
      "  [ 74]\n",
      "  [156]\n",
      "  [114]\n",
      "  [ 35]\n",
      "  [ 72]\n",
      "  [ 71]\n",
      "  [ 75]\n",
      "  [ 78]\n",
      "  [ 72]\n",
      "  [ 66]\n",
      "  [ 80]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 64]\n",
      "  [ 63]\n",
      "  [165]\n",
      "  [119]\n",
      "  [ 68]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 23]\n",
      "  [ 85]\n",
      "  [ 81]\n",
      "  [177]\n",
      "  [ 57]\n",
      "  [ 52]\n",
      "  [ 77]\n",
      "  [ 71]\n",
      "  [ 78]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 64]\n",
      "  [ 37]\n",
      "  [173]\n",
      "  [ 95]\n",
      "  [ 72]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 26]\n",
      "  [ 81]\n",
      "  [ 86]\n",
      "  [160]\n",
      "  [ 20]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 78]\n",
      "  [ 80]\n",
      "  [ 89]\n",
      "  [ 78]\n",
      "  [ 81]\n",
      "  [ 83]\n",
      "  [ 80]\n",
      "  [ 74]\n",
      "  [ 20]\n",
      "  [177]\n",
      "  [ 77]\n",
      "  [ 74]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 49]\n",
      "  [ 77]\n",
      "  [ 91]\n",
      "  [200]\n",
      "  [  0]\n",
      "  [ 83]\n",
      "  [ 95]\n",
      "  [ 86]\n",
      "  [ 88]\n",
      "  [ 88]\n",
      "  [ 89]\n",
      "  [ 88]\n",
      "  [ 89]\n",
      "  [ 88]\n",
      "  [ 83]\n",
      "  [ 89]\n",
      "  [ 86]\n",
      "  [  0]\n",
      "  [191]\n",
      "  [ 78]\n",
      "  [ 80]\n",
      "  [ 24]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 54]\n",
      "  [ 71]\n",
      "  [108]\n",
      "  [165]\n",
      "  [  0]\n",
      "  [ 24]\n",
      "  [ 57]\n",
      "  [ 52]\n",
      "  [ 57]\n",
      "  [ 60]\n",
      "  [ 60]\n",
      "  [ 60]\n",
      "  [ 63]\n",
      "  [ 63]\n",
      "  [ 77]\n",
      "  [ 89]\n",
      "  [ 52]\n",
      "  [  0]\n",
      "  [211]\n",
      "  [ 97]\n",
      "  [ 77]\n",
      "  [ 61]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 68]\n",
      "  [ 91]\n",
      "  [117]\n",
      "  [137]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [216]\n",
      "  [ 94]\n",
      "  [ 97]\n",
      "  [ 57]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 54]\n",
      "  [115]\n",
      "  [105]\n",
      "  [185]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  1]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [153]\n",
      "  [ 78]\n",
      "  [106]\n",
      "  [ 37]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [ 61]\n",
      "  [ 41]\n",
      "  [103]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [106]\n",
      "  [ 47]\n",
      "  [ 69]\n",
      "  [ 23]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]], shape=(28, 28, 1), dtype=uint8)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 15:43:50.274989: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for item in mnist_train.take(1):\n",
    "    print(type(item))\n",
    "    print(item.keys())\n",
    "    print(item['image'])\n",
    "    print(item['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='fashion_mnist',\n",
      "    full_name='fashion_mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
      "    \"\"\",\n",
      "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
      "    data_path='/home/babi/tensorflow_datasets/fashion_mnist/3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=29.45 MiB,\n",
      "    dataset_size=36.42 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
      "      author    = {Han Xiao and\n",
      "                   Kashif Rasul and\n",
      "                   Roland Vollgraf},\n",
      "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
      "                   Algorithms},\n",
      "      journal   = {CoRR},\n",
      "      volume    = {abs/1708.07747},\n",
      "      year      = {2017},\n",
      "      url       = {http://arxiv.org/abs/1708.07747},\n",
      "      archivePrefix = {arXiv},\n",
      "      eprint    = {1708.07747},\n",
      "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
      "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
      "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mnist_test, info = tfds.load(name=\"fashion_mnist\", with_info=\"true\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = tfds.as_numpy(tfds.load('fashion_mnist',\n",
    "    split = ['train', 'test'],\n",
    "    batch_size=-1,\n",
    "    as_supervised=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 153.59 MiB (download: 153.59 MiB, generated: Unknown size, total: 153.59 MiB) to /home/babi/tensorflow_datasets/horses_or_humans/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59b81050e5a478cbf868ad2c4b31537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb82365585e4b8e8f031c3a91cc75f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e3ffa4ce88470a8ee314885b15a106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814bbdfdea3c45c29c73eb29b2efa05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/1027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35eea51fe8b94b9092fde5e0a7330ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/babi/tensorflow_datasets/horses_or_humans/3.0.0.incompleteAAR18F/horses_or_humans-train.tfreco…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2bd0727ce544d5b57f807aa81038c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104f29b83f5546f3937ee8c7eb26fc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/babi/tensorflow_datasets/horses_or_humans/3.0.0.incompleteAAR18F/horses_or_humans-test.tfrecor…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset horses_or_humans downloaded and prepared to /home/babi/tensorflow_datasets/horses_or_humans/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - 59s 548ms/step - loss: 1.5915 - accuracy: 0.8520\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - 53s 514ms/step - loss: 0.0912 - accuracy: 0.9669\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - 57s 554ms/step - loss: 0.0560 - accuracy: 0.9815\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - 56s 541ms/step - loss: 0.0664 - accuracy: 0.9805\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - 50s 484ms/step - loss: 0.0397 - accuracy: 0.9873\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - 50s 489ms/step - loss: 0.0332 - accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - 52s 503ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "103/103 [==============================] - 55s 530ms/step - loss: 1.0734e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "103/103 [==============================] - 54s 522ms/step - loss: 7.4257e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "103/103 [==============================] - 58s 567ms/step - loss: 5.4365e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "data = tfds.load('horses_or_humans', split='train', as_supervised=True)\n",
    "train_batches = data.shuffle(100).batch(10)\n",
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Conv2D(16, (3,3), activation='relu',\n",
    "input_shape=(300, 300, 3)),\n",
    "tf.keras.layers.MaxPooling2D(2, 2),\n",
    "tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Flatten(),\n",
    "tf.keras.layers.Dense(512, activation='relu'),\n",
    "tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "history = model.fit(train_batches, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = tfds.load('horses_or_humans', split='test', as_supervised=True)\n",
    "validation_batches = val_data.batch(32)\n",
    "\n",
    "history = model.fit(train_batches, epochs=10,\n",
    "validation_data=validation_batches, validation_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Mapping Functions for Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tfds.load('horses_or_humans', split='train', as_supervised=True)\n",
    "train_batches = data.shuffle(100).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentimages(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/255)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.map(augmentimages)\n",
    "train_batches = train.shuffle(100).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TensorFlow Addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/babi/miniconda3/envs/tensor/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def augmentimages(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/255)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tfa.image.rotate(image, 40, interpolation=\"NEAREST\")\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tfds.load('cats_vs_dogs', split='train[:80%]',\n",
    "as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = [i for i,_ in enumerate(train_data)][-1] + 1\n",
    "print(train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = tfds.load(\"mnist\", with_info=True)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"/root/tensorflow_datasets/mnist/3.0.0/mnist-test.tfrecord-00000-of-00001\"\n",
    "raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "for raw_record in raw_dataset.take(1):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features\n",
    "feature_description = {\n",
    "'image': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "'label': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "}\n",
    "def _parse_function(example_proto):\n",
    "    # Parse the input `tf.Example` proto using the dictionary above\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "for parsed_record in parsed_dataset.take(1):\n",
    "    print((parsed_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ETL Process for Managing Data in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33/33 [==============================] - 57s 2s/step - loss: 0.4511 - accuracy: 0.7751 - val_loss: 132.3650 - val_accuracy: 0.6250\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:15:16.388804: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 54s 2s/step - loss: 0.1772 - accuracy: 0.9318 - val_loss: 558.6813 - val_accuracy: 0.3438\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:16:10.510678: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 55s 2s/step - loss: 0.0535 - accuracy: 0.9786 - val_loss: 715.0818 - val_accuracy: 0.5938\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:17:05.095524: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:18:02.237715: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 57s 2s/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 578.4860 - val_accuracy: 0.6562\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 683.2153 - val_accuracy: 0.5625\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:18:58.619509: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 58s 2s/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 597.0817 - val_accuracy: 0.6562\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:19:56.952794: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 55s 2s/step - loss: 0.0288 - accuracy: 0.9883 - val_loss: 470.5539 - val_accuracy: 0.4688\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:20:51.612069: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 56s 2s/step - loss: 0.0363 - accuracy: 0.9825 - val_loss: 632.0110 - val_accuracy: 0.4688\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:21:47.340741: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/33 [========================>.....] - ETA: 8s - loss: 0.0281 - accuracy: 0.9955"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "# MODEL DEFINITION START #\n",
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Conv2D(16, (3,3), activation='relu',\n",
    "input_shape=(300, 300, 3)),\n",
    "tf.keras.layers.MaxPooling2D(2, 2),\n",
    "tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Flatten(),\n",
    "tf.keras.layers.Dense(512, activation='relu'),\n",
    "tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "# MODEL DEFINITION END #\n",
    "# EXTRACT PHASE START #\n",
    "data = tfds.load('horses_or_humans', split='train', as_supervised=True)\n",
    "val_data = tfds.load('horses_or_humans', split='test', as_supervised=True)\n",
    "# EXTRACT PHASE END\n",
    "# TRANSFORM PHASE START #\n",
    "def augmentimages(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/255)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tfa.image.rotate(image, 40, interpolation='NEAREST')\n",
    "    return image, label\n",
    "\n",
    "train = data.map(augmentimages)\n",
    "train_batches = train.shuffle(100).batch(32)\n",
    "validation_batches = val_data.batch(32)\n",
    "\n",
    "# TRANSFORM PHASE END\n",
    "# LOAD PHASE START #\n",
    "history = model.fit(train_batches, epochs=10,\n",
    "validation_data=validation_batches, validation_steps=1)\n",
    "# LOAD PHASE END #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing ETL to Improve Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tfds.load('cats_vs_dogs', split='train', with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = '/root/tensorflow_datasets/cats_vs_dogs/4.0.0/cats_vs_dogs-train.tfrecord*'\n",
    "files = tf.data.Dataset.list_files(file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = files.interleave(\n",
    "    tf.data.TFRecordDataset,\n",
    "    cycle_length=4,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description={\n",
    "    \"image\": tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "    \"label\": tf.io.FixedLenFeature((), tf.int64, -1),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(\n",
    "    serialized_example, feature_description\n",
    "    )\n",
    "    image = tf.io.decode_jpeg(example['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255\n",
    "    image = tf.image.resize(image, (300,300))\n",
    "    return image, example['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "print(cores)\n",
    "train_dataset = train_dataset.map(read_tfrecord, num_parallel_calls=cores)\n",
    "train_dataset = train_dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "model.fit(train_dataset, epochs=10, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
